{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, MACCSkeys\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_version_1_path = \"../data_for_modeling/raw_data/v1/Original Data - v1 - Merge.xlsx\"\n",
    "dataset = pd.read_excel(data_version_1_path, sheet_name='original_data')\n",
    "dataset_length = len(dataset)\n",
    "dataset_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Group by original activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_table_for_activity_counts(dataset, col_name):\n",
    "    active_rows = dataset.loc[dataset[col_name] == \"Active\"]\n",
    "    inactive_rows = dataset.loc[dataset[col_name] == \"Inactive\"]\n",
    "    inconclusive_rows = dataset.loc[dataset[col_name] == \"Inconclusive\"]\n",
    "    unspecified_rows = dataset.loc[dataset[col_name] == \"Unspecified\"]\n",
    "\n",
    "    print(\"Total dataset\")\n",
    "    table = [['', 'Active', 'Inactive', 'Inconclusive', 'Unspecified'], \n",
    "            ['Number', len(active_rows), len(inactive_rows), len(inconclusive_rows), len(unspecified_rows)],\n",
    "            ['Percentage (%)', len(active_rows)/dataset_length*100, len(inactive_rows)/dataset_length*100,\n",
    "            len(inconclusive_rows)/dataset_length*100, len(unspecified_rows)/dataset_length*100]]\n",
    "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset\n",
      "╒════════════════╤══════════╤════════════╤════════════════╤═══════════════╕\n",
      "│                │   Active │   Inactive │   Inconclusive │   Unspecified │\n",
      "╞════════════════╪══════════╪════════════╪════════════════╪═══════════════╡\n",
      "│ Number         │ 769      │   10       │              0 │      214      │\n",
      "├────────────────┼──────────┼────────────┼────────────────┼───────────────┤\n",
      "│ Percentage (%) │  77.4421 │    1.00705 │              0 │       21.5509 │\n",
      "╘════════════════╧══════════╧════════════╧════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "draw_table_for_activity_counts(dataset=dataset, col_name='FIRST_LABEL')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Group by the new activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset\n",
      "╒════════════════╤══════════╤════════════╤════════════════╤═══════════════╕\n",
      "│                │   Active │   Inactive │   Inconclusive │   Unspecified │\n",
      "╞════════════════╪══════════╪════════════╪════════════════╪═══════════════╡\n",
      "│ Number         │ 501      │   492      │              0 │             0 │\n",
      "├────────────────┼──────────┼────────────┼────────────────┼───────────────┤\n",
      "│ Percentage (%) │  50.4532 │    49.5468 │              0 │             0 │\n",
      "╘════════════════╧══════════╧════════════╧════════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "draw_table_for_activity_counts(dataset=dataset, col_name='ACTIVITY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cannonical Smiles and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_canonical_smiles(smiles):\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in smiles]\n",
    "    smiles = [Chem.MolToSmiles(mol) for mol in mols]\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CC(Nc1ccccc1)c1ccc(C(=O)Nc2ccccc2N)cc1',\n",
       "       'CC(Nc1ccccc1)c1ccc(C(=O)Nc2ccccc2N)cc1',\n",
       "       'O=C1CCC=CCCC(=O)N(Cc2cccc(C=NNC(=O)c3cccc(C(=O)NO)c3)c2)CC(c2ccccc2)O1',\n",
       "       'CC(C)C1NC(=O)C2(C)CSC(=N2)c2csc(n2)CNC(=O)CC(C(F)=CCCS)OC1=O',\n",
       "       'O=C(CCC(CCCC(=O)Nc1ccccc1)Cc1ccccc1)NO',\n",
       "       'O=C(CCC(CCCC(=O)Nc1ccccc1)Cc1ccccc1)NO',\n",
       "       'CCCCCCC(CCCCCC(=O)Nc1ccccc1)C(=O)NO',\n",
       "       'COc1ccc(COC(CCCCCC(=O)NO)C(=O)Nc2ccccc2)cc1',\n",
       "       'COc1ccc(COC(CCCCCC(=O)NO)C(=O)Nc2ccccc2)cc1'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cannon_smiles = make_canonical_smiles(dataset.SMILES)\n",
    "dataset['SMILES'] = cannon_smiles\n",
    "duplicates_smiles = dataset[dataset['SMILES'].duplicated()]['SMILES'].values\n",
    "duplicates_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249, 252, 270, 249, 252, 270, 260, 290, 704, 706, 910, 912, 913, 910, 912, 913, 915, 917, 974, 975, 977, 974, 975, 977]\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "dup_smiles_idxs = []\n",
    "for smiles in duplicates_smiles:\n",
    "    sub_dataset_dup_smiles = dataset[dataset.SMILES == smiles].copy()\n",
    "    for idx, _ in sub_dataset_dup_smiles.iterrows():\n",
    "        dup_smiles_idxs.append(idx)\n",
    "print(dup_smiles_idxs)\n",
    "print(len(dup_smiles_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(dup_smiles_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check again\n",
    "duplicates_smiles = dataset[dataset['SMILES'].duplicated()]['SMILES'].values\n",
    "duplicates_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check for label intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "active_rows = dataset.loc[dataset['FIRST_LABEL'] == \"Active\"]\n",
    "inactive_rows = dataset.loc[dataset['FIRST_LABEL'] == \"Inactive\"]\n",
    "inconclusive_rows = dataset.loc[dataset['FIRST_LABEL'] == \"Inconclusive\"]\n",
    "unspecified_rows = dataset.loc[dataset['FIRST_LABEL'] == \"Unspecified\"]\n",
    "    \n",
    "cid_active = active_rows.loc[:, 'CID']\n",
    "cid_inactive = inactive_rows.loc[:, 'CID']\n",
    "cid_incon = inconclusive_rows.loc[:, 'CID']\n",
    "cid_unspec = unspecified_rows.loc[:, 'CID']\n",
    "\n",
    "ac_inac_cid = np.intersect1d(cid_active, cid_inactive)\n",
    "ac_incon_cid = np.intersect1d(cid_active, cid_incon)\n",
    "ac_unspec_cid = np.intersect1d(cid_active, cid_unspec)\n",
    "\n",
    "inac_incon_cid = np.intersect1d(cid_inactive, cid_incon)\n",
    "incon_unspec_cid = np.intersect1d(cid_incon, cid_unspec)\n",
    "inac_unspec_cid = np.intersect1d(cid_inactive, cid_unspec)\n",
    "print(len(ac_inac_cid), \n",
    "      len(ac_incon_cid), \n",
    "      len(ac_unspec_cid), \n",
    "      len(inac_incon_cid), \n",
    "      len(incon_unspec_cid), \n",
    "      len(inac_unspec_cid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Labels errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STT</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>CID</th>\n",
       "      <th>IC50 (uM)</th>\n",
       "      <th>FIRST_LABEL</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>DUPLICATE_COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>COC(=O)CCNNC(=O)C=Cc1ccc(CNCCc2c(C)[nH]c3ccccc...</td>\n",
       "      <td>155525662</td>\n",
       "      <td>4.21400</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CSc1ccc2c(c1)N(Cc1ccc(C(=O)NO)cc1)c1ccccc1S2</td>\n",
       "      <td>164629157</td>\n",
       "      <td>0.68000</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>O=C(NO)c1ccc(CN2c3ccccc3S(=O)c3ccc(C(F)(F)F)cc...</td>\n",
       "      <td>164627475</td>\n",
       "      <td>2.12000</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CC(C)(C)OC(=O)Nc1ccc(-c2cc(NC(=O)CCCCCCC(=O)NO...</td>\n",
       "      <td>164627446</td>\n",
       "      <td>0.25200</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CCCC[C@H](NC(=O)[C@H](CN)c1c(C)[nH]c2ccc(OC)cc...</td>\n",
       "      <td>164627330</td>\n",
       "      <td>2.00525</td>\n",
       "      <td>Active</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STT                                             SMILES        CID  \\\n",
       "0    0  COC(=O)CCNNC(=O)C=Cc1ccc(CNCCc2c(C)[nH]c3ccccc...  155525662   \n",
       "1    1       CSc1ccc2c(c1)N(Cc1ccc(C(=O)NO)cc1)c1ccccc1S2  164629157   \n",
       "2    2  O=C(NO)c1ccc(CN2c3ccccc3S(=O)c3ccc(C(F)(F)F)cc...  164627475   \n",
       "3    3  CC(C)(C)OC(=O)Nc1ccc(-c2cc(NC(=O)CCCCCCC(=O)NO...  164627446   \n",
       "4    4  CCCC[C@H](NC(=O)[C@H](CN)c1c(C)[nH]c2ccc(OC)cc...  164627330   \n",
       "\n",
       "   IC50 (uM) FIRST_LABEL ACTIVITY  DUPLICATE_COUNTS  \n",
       "0    4.21400      Active        0                 1  \n",
       "1    0.68000      Active        1                 1  \n",
       "2    2.12000      Active        0                 1  \n",
       "3    0.25200      Active        1                 1  \n",
       "4    2.00525      Active        0                 4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encoding labels\n",
    "dataset.loc[dataset.ACTIVITY == 'Active', 'ACTIVITY'] = 1\n",
    "dataset.loc[dataset.ACTIVITY == 'Inactive', 'ACTIVITY'] = 0\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will do this in the MACCS keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maccs_fpts(data):\n",
    "    Maccs_fpts = []\n",
    "    for i in data:\n",
    "        mol = Chem.MolFromSmiles(i)\n",
    "        fpts = MACCSkeys.GenMACCSKeys(mol)\n",
    "        mfpts = np.array(fpts)\n",
    "        Maccs_fpts.append(mfpts)\n",
    "    return np.array(Maccs_fpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  157  158  159  160  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    1    1    1    1   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    1    1    1   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    1    1    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    1    1    1    1   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    1    1    1    1   \n",
       "\n",
       "   161  162  163  164  165  166  \n",
       "0    1    1    1    1    1    1  \n",
       "1    1    1    1    1    1    0  \n",
       "2    1    1    1    1    1    0  \n",
       "3    1    1    1    1    1    0  \n",
       "4    1    1    1    1    1    0  \n",
       "\n",
       "[5 rows x 167 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = dataset.SMILES\n",
    "data = maccs_fpts(smiles)\n",
    "data = pd.DataFrame(data=data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = dataset['ACTIVITY']\n",
    "labels = np.array(labels, dtype=int)\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Getting out-of-sample predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost(experimental) supports categorical data.\n",
    "# Here we use default hyperparameters for simplicity.\n",
    "# Get out-of-sample predicted probabilities and check model accuracy.\n",
    "model = XGBClassifier(tree_method=\"hist\", enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978\n",
      "[[0.09393412 0.9060659 ]\n",
      " [0.9435409  0.05645914]\n",
      " [0.01030552 0.9896945 ]\n",
      " ...\n",
      " [0.9601505  0.03984953]\n",
      " [0.8757034  0.12429662]\n",
      " [0.9674798  0.03252017]]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = cross_val_predict(model, data, labels, method='predict_proba')\n",
    "print(len(pred_probs))\n",
    "print(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels)\n",
    "preds = model.predict(data)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9703476482617587"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels, preds) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Checking model accuracy on original data\n",
    "\n",
    "Now that we have out-of-sample predicted probabilities, we can also check the model's (cross-val) accuracy on the original (noisy) data, so we'll have a baseline to compare our final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1\n",
      " 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 0\n",
      " 0 1 0 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 0\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 1 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1\n",
      " 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0\n",
      " 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
      " 1 1 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1\n",
      " 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0\n",
      " 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0\n",
      " 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0\n",
      " 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1\n",
      " 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 0 0 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 1 1 0 0 1 1 1\n",
      " 0 0 0 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0\n",
      " 0 1 1 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0\n",
      " 1 0 1 1 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(pred_probs, axis=1)\n",
    "preds = np.array(preds, dtype=int)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with original data: 63.5%\n"
     ]
    }
   ],
   "source": [
    "acc_original = accuracy_score(preds, labels)\n",
    "print(f\"Accuracy with original data: {round(acc_original*100,1)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Finding label issues automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978 2\n"
     ]
    }
   ],
   "source": [
    "n_examples, n_classes = pred_probs.shape\n",
    "print(n_examples, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_thresholds(pred_probs: np.ndarray, labels: np.ndarray) -> np.ndarray:\n",
    "    n_examples, n_classes = pred_probs.shape\n",
    "    thresholds = np.zeros(n_classes)\n",
    "    for k in range(n_classes):\n",
    "        count = 0\n",
    "        p_sum = 0\n",
    "        for i in range(n_examples):\n",
    "            if labels[i] == k: #this explain the p^(y~=j;x,theta), the noisy label is equal class k\n",
    "                count += 1\n",
    "                p_sum += pred_probs[i, k]\n",
    "        thresholds[k] = p_sum / count\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61931538, 0.61794919])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be a numpy array of length 5\n",
    "thresholds = compute_class_thresholds(pred_probs, labels)\n",
    "thresholds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Constructing the confident joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confident_joint(pred_probs: np.ndarray, labels: np.ndarray, thresholds: np.ndarray) -> np.ndarray:\n",
    "    n_examples, n_classes = pred_probs.shape\n",
    "    confident_joint = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "    for data_idx in range(n_examples):\n",
    "        i = labels[data_idx]    #y_noise\n",
    "        j = None                #y_true -> to find\n",
    "        #Lưu ý điểm mình bị sai: vị trí của chúng không ứng với label\n",
    "        p_j = -1\n",
    "        for candidate_j in range(n_classes):\n",
    "            p = pred_probs[data_idx, candidate_j]\n",
    "            if p >= thresholds[candidate_j] and p > p_j:\n",
    "                j = candidate_j\n",
    "                p_j = p\n",
    "        if j is not None:\n",
    "            confident_joint[i][j] += 1\n",
    "    return confident_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\MachineLearning\\JupyterNotebook\\Pharmacy\\My HDAC2\\src\\my-hdac2-clean-data.ipynb Cell 42\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Code/MachineLearning/JupyterNotebook/Pharmacy/My%20HDAC2/src/my-hdac2-clean-data.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m C \u001b[39m=\u001b[39m compute_confident_joint(pred_probs, labels\u001b[39m.\u001b[39mto_numpy(), thresholds)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/MachineLearning/JupyterNotebook/Pharmacy/My%20HDAC2/src/my-hdac2-clean-data.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m C\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "C = compute_confident_joint(pred_probs, labels.to_numpy(), thresholds)\n",
    "C"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
