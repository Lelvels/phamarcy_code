{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, MACCSkeys\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "from mordred import Calculator, descriptors\n",
    "import sklearn.preprocessing as preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = \"../../data_for_modeling/filter_data/v1/clean_data/HDAC2_train_test_clean_data.xlsx\"; \n",
    "train_dataset = pd.read_excel(train_test_path, sheet_name='train_dataset')\n",
    "test_dataset = pd.read_excel(train_test_path, sheet_name='test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Xây dựng mô hình với Modred descriptors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Tính toán mordred descriptors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mã hóa cấu trúc phân tử bằng Modred descriptors__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use this for new data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_modred(data):\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    mols = [Chem.MolFromSmiles(smi) for smi in data]\n",
    "    # pandas df\n",
    "    df = calc.pandas(mols)\n",
    "    return df\n",
    "\n",
    "train_modred_descriptors = process_modred(train_dataset['SMILES'])\n",
    "test_mordred_descriptors = process_modred(test_dataset['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modred_descriptors.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Use this when already have file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_modred_descriptors = pd.read_excel('../data_for_modeling/filter_data/v1/modred_descriptors_out.xlsx', sheet_name=\"train_modred_descriptors\")\n",
    "# test_mordred_descriptors = pd.read_excel('../data_for_modeling/filter_data/v1/modred_descriptors_out.xlsx', sheet_name=\"test_modred_descriptor\")\n",
    "# train_modred_descriptors = pd.DataFrame(train_modred_descriptors)\n",
    "# test_mordred_descriptors = pd.DataFrame(test_mordred_descriptors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Làm sạch dữ liệu__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Do thuật toán mã hóa Modred không thể tìm được mọi features của SMILES nên sẽ có một số chỗ không phải là số thực mà là một object báo lỗi, ta sẽ loại bỏ tất cả object báo lỗi này.\n",
    "- Các dữ liệu sau khi xử lý có giá trị khác numpy.float64 và numpy.int64 thì cho bằng 0.\n",
    "- Toàn bộ dữ liệu ta xử lý đều là dữ liệu số, vì vậy ta sẽ đặt những object này với giá trị bằng 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = np.array(train_modred_descriptors)\n",
    "test_np = np.array(test_mordred_descriptors)\n",
    "for (row, col), value in np.ndenumerate(train_np):\n",
    "    if not (value.__class__ in [int, float, np.float64, np.float32, np.int64, np.int32]):\n",
    "        train_np[row, col] = 0\n",
    "        \n",
    "for (row, col), value in np.ndenumerate(test_np):\n",
    "    if not (value.__class__ in [int, float, np.float64, np.float32, np.int64, np.int32]):\n",
    "        test_np[row, col] = 0\n",
    "\n",
    "train_modred_descriptors = pd.DataFrame(train_np, columns=train_modred_descriptors.columns)\n",
    "test_mordred_descriptors = pd.DataFrame(test_np, columns=test_mordred_descriptors.columns)\n",
    "all_mordred_descriptors = pd.concat([train_modred_descriptors, test_mordred_descriptors], ignore_index=False)\n",
    "# Write to file\n",
    "# train_modred_descriptors.to_csv(\"../output/modred_des/train_modred_des_unspec_removed(1).csv\", index=False)\n",
    "# test_mordred_descriptors.to_csv(\"../output/modred_des/test_modred_des_unspec_removed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modred_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mordred_descriptors.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Import and encoding y</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_dataset['ACTIVITY'])\n",
    "y_test = np.array(test_dataset['ACTIVITY'])\n",
    "y_all = np.append(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0:5])\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = preprocessing.LabelEncoder().fit_transform(y_train)\n",
    "y_test = preprocessing.LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0:5])\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train), len(y_test), len(y_all))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Tiền xử lý dữ liệu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo ma trận features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic50_train = np.array(train_dataset['IC50 (uM)'])\n",
    "for i, value in np.ndenumerate(ic50_train):\n",
    "    if not (value.__class__ in [int, float, np.float64, np.float32, np.int64, np.int32]):\n",
    "        ic50_train[i] = 0\n",
    "print(len(ic50_train))\n",
    "print(ic50_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "train_modred_descriptors['IC50'] = ic50_train\n",
    "sc = StandardScaler()\n",
    "train_modred_np = sc.fit_transform(train_modred_descriptors)\n",
    "train_modred_descriptors = pd.DataFrame(train_modred_np, columns=train_modred_descriptors.columns)\n",
    "corr_matrix = train_modred_descriptors.corr(method=\"pearson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modred_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix.to_excel(\"../output/corr_matrix/unclean_data/HDAC2_corr_matrix_with_unclean_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = corr_matrix.dropna(subset=['IC50'])\n",
    "print(len(corr_matrix))\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic50_corrs_abs = corr_matrix['IC50'].abs()\n",
    "features = corr_matrix.loc[ic50_corrs_abs > 0.05, :].index.tolist()\n",
    "sorted_corr_matrix = corr_matrix.loc[features, features]\n",
    "\n",
    "sorted_corr_matrix = sorted_corr_matrix.sort_values(by='IC50', ascending=False)\n",
    "index_order = sorted_corr_matrix.index.tolist()\n",
    "sorted_corr_matrix = sorted_corr_matrix[index_order].reindex(index_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_zero_diagonal(sorted_corr_matrix):\n",
    "    col_idx = 0\n",
    "    arr = []\n",
    "    for index, row in sorted_corr_matrix.iterrows():\n",
    "        row.iloc[col_idx] = 0\n",
    "        col_idx+=1\n",
    "    return sorted_corr_matrix\n",
    "\n",
    "upper_triangle = sorted_corr_matrix.where(np.triu(np.ones(sorted_corr_matrix.shape)).astype(bool))\n",
    "upper_triangle = upper_triangle.fillna(0)\n",
    "upper_triangle = set_zero_diagonal(upper_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(upper_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(upper_triangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_triangle.to_excel(\"../output/corr_matrix/HDAC2_upper_triangle_unspec_removed(1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(sorted_df, pcc_point):\n",
    "    above_pcc_point = (sorted_df > pcc_point) | (sorted_df < -pcc_point)\n",
    "    shapes = [] \n",
    "    features = []\n",
    "    dropped_features = set()\n",
    "    for idx, row in sorted_df.iterrows():\n",
    "        if idx in dropped_features:\n",
    "            continue\n",
    "        print(\"[+] Working with row: \" + idx)\n",
    "        cols_rows_to_drop = []\n",
    "        for col in sorted_df.columns:\n",
    "            if above_pcc_point.loc[idx, col]:\n",
    "                cols_rows_to_drop.append(col)\n",
    "        # drop the columns\n",
    "        print(\"[-] Detected in this row:\")\n",
    "        print(cols_rows_to_drop)\n",
    "        for col_row_index in cols_rows_to_drop:\n",
    "            dropped_features.add(col_row_index)\n",
    "        #Drop the data\n",
    "        sorted_df = sorted_df.drop(cols_rows_to_drop, axis=1).drop(cols_rows_to_drop, axis=0)\n",
    "        shapes.append(sorted_df.shape)\n",
    "        features.append(sorted_df.index.to_list())  \n",
    "        # check if there are any rows left\n",
    "        if len(sorted_df) == 0:\n",
    "            break\n",
    "    return sorted_df, shapes, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcc_point = 0.95\n",
    "matrix_before_processing = upper_triangle.iloc[1:, 1:]\n",
    "result_matrix, shapes, features = remove_correlated_features(matrix_before_processing, pcc_point=pcc_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_features = result_matrix.columns.to_list()\n",
    "lengths = []\n",
    "features_to_file = []\n",
    "tmp_features = []\n",
    "for features in result_features:\n",
    "    tmp_features.append(features)\n",
    "    lengths.append(len(tmp_features))\n",
    "    features_to_file.append(tmp_features.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pcc_matrix_fp = \"../output/pcc_processed_matrix/\"+str(pcc_point)+\"_pcc_processed_matrix_unspec_removed(1).xlsx\"\n",
    "shapes_and_features_fp = \"../output/shapes_and_features/\"+str(pcc_point)+\"_shapes_and_features_unspec_removed(1).xlsx\"\n",
    "#Write to file processed pcc matrix\n",
    "result_matrix['IC50'] = upper_triangle.iloc[0]\n",
    "result_matrix.to_excel(processed_pcc_matrix_fp, index=True)\n",
    "\n",
    "# create a DataFrame with the shapes and features\n",
    "df_shapes = pd.DataFrame({'Len': lengths, 'Features': features_to_file})\n",
    "# write the DataFrame to an Excel file\n",
    "df_shapes.to_excel(shapes_and_features_fp, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the optimal features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_data = pd.read_excel('../output/shapes_and_features.xlsx', sheet_name='Sheet1')\n",
    "# features_strings = features_data['Features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ast\n",
    "# list_of_features = []\n",
    "# for features_string in features_strings:\n",
    "#     list_of_features.append(ast.literal_eval(features_string))\n",
    "\n",
    "# features = list_of_features[0]\n",
    "# len(list_of_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_features = ['Xc-4dv', 'MATS4s', 'GATS1dv', 'SdssC', 'BCUTd-1h', 'GATS1s', 'GATS1are', 'AATSC3d'\n",
    "#                     , 'PEOE_VSA2', 'AATS4v', 'AATS4Z', 'GATS3d', 'MATS3m', 'AXp-5dv', 'EState_VSA4',\n",
    "#                     'ETA_eta_L', 'ATSC5m', 'RotRatio', 'SsNH2', 'ETA_epsilon_5', 'SlogP_VSA2',\n",
    "#                     'MID_N', 'EState_VSA5', 'Xc-5dv', 'JGI5', 'GATS5pe', 'AATSC4d']\n",
    "authors_features = ['nSpiro', 'C4SP3', 'GATS8s', 'n5ARing', 'SssCH2', 'nARing', 'Xpc-5dv', 'ATSC3d', 'Xc-4dv', 'ATSC5d', 'SMR_VSA4', 'GATS8se', 'n5AHRing', 'MDEC-24', 'ATSC6v', 'GATS2d', 'n6ARing', 'ATSC3v', 'nAHRing', 'ATSC6m', 'nHRing', 'ATSC2d', 'PEOE_VSA7', 'Xc-3dv', 'SMR_VSA6', 'GATS4dv', 'MATS4s']\n",
    "len(authors_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_modred_descriptors[authors_features]\n",
    "X_test = test_mordred_descriptors[authors_features]\n",
    "print(X_train.columns)\n",
    "print(X_test.columns)\n",
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_np = sc.fit_transform(X_train)\n",
    "X_test_np = sc.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train_np, columns = X_train.columns)\n",
    "X_test = pd.DataFrame(X_test_np, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Xây dựng mô hình"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_des_author = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "rf_des_author.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_des_author = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)\n",
    "knn_des_author.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_des_author = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "svm_des_author.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "bst_des_author = XGBClassifier(n_estimators=100, objective='binary:logistic')\n",
    "bst_des_author.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Đánh giá mô hình"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Total = np.concatenate((X_train, X_test), axis=0)\n",
    "y_Total = np.concatenate((y_train, y_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "scores = cross_val_score(knn_des_author, X_Total, y_Total, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Độ chính xác của 10-fold cross validation: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(rf_des_author, X_Total, y_Total, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Độ chính xác của 10-fold cross validation: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(svm_des_author, X_Total, y_Total, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Độ chính xác của 10-fold cross validation: %.3f (%.3f)' % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(bst_des_author, X_Total, y_Total, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Độ chính xác của 10-fold cross validation: %.3f (%.3f)' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, Sensitivity, Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tabulate import tabulate\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation_calculation(cm):\n",
    "    tp = cm[0][0]; tn = cm[1][1]; fp = cm[0][1]; fn = cm[1][0]\n",
    "    ac = (tp+tn)/(tp+tn+fp+fn)\n",
    "    se = tp/(tp+fn)\n",
    "    sp = tn/(tn+fp)\n",
    "    mcc = (tp*tn - fp*fn) / math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n",
    "    return ac, se, sp, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def me_result(cm):\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(cm)\n",
    "    ac, se, sp, mcc = model_evaluation_calculation(cm)\n",
    "    print(\"Comparision:\")\n",
    "    table = [[' ' 'Accuracy', 'Sensitity', 'Specificity', 'MCC'], ['My model', ac, se, sp, mcc]]\n",
    "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "y_knn_pred = knn_des_author.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_knn_pred)\n",
    "me_result(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "y_rf_pred = rf_des_author.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_rf_pred)\n",
    "me_result(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "y_svm_pred = svm_des_author.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_svm_pred)\n",
    "me_result(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bst_pred = bst_des_author.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_bst_pred)\n",
    "me_result(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "knn_y_proba = knn_des_author.predict_proba(X_test)[:, 1]\n",
    "rf_y_proba = rf_des_author.predict_proba(X_test)[:, 1]\n",
    "svm_y_proba = svm_des_author.predict_proba(X_test)[:, 1]\n",
    "bst_y_proba = bst_des_author.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "knn_auc_score = roc_auc_score(y_test, knn_y_proba)\n",
    "rf_auc_score = roc_auc_score(y_test, rf_y_proba)\n",
    "svm_auc_score = roc_auc_score(y_test, svm_y_proba)\n",
    "bst_auc_score = roc_auc_score(y_test, bst_y_proba)\n",
    "print(knn_auc_score, rf_auc_score, svm_auc_score, bst_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    estimator=rf_des_author, \n",
    "    X=X_test, \n",
    "    y=y_test,\n",
    "    name=f\"ROC curve for RF\",\n",
    "    color='cornflowerblue',\n",
    "    ax=ax)\n",
    "\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    estimator=knn_des_author, \n",
    "    X=X_test, \n",
    "    y=y_test,\n",
    "    name=f\"ROC curve for KNN\",\n",
    "    color='darkorange',\n",
    "    ax=ax)\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    estimator=bst_des_author, \n",
    "    X=X_test, \n",
    "    y=y_test,\n",
    "    name=f\"ROC curve for XGBoost\",\n",
    "    color='aqua',\n",
    "    ax=ax)\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    estimator=svm_des_author, \n",
    "    X=X_test, \n",
    "    y=y_test,\n",
    "    name=f\"ROC curve for SVM\",\n",
    "    color='red',\n",
    "    ax=ax)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Modred Descriptors ROC Curves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9261f96c4a796f57ae4bca1e6085db69d1e98c41d8f6e6360d996db9421903c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
